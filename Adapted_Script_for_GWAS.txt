
################ Explanation of the main script ##########################

This code has been adapted from a tutorial provided by Marees et al., 2018. Adapatations were made for use on the UKB dataset and for a linear AUDIT Score.
FULL CREDIT FOR THIS CODE AND PIPELINE IS GIVEN TO MAREES ET AL. 2018.
This code details the process of performing a Genome Wide Association Study for a quantitative AUDIT score phenotype.
Input file - initial input file contains all extracted fields (as per methods section of the thesis provided by Hugh Gallagher) with total AUDIT score calculated as a sum of Questions 1-10.
		The input file must be converted to Plink compatible format of .bim .bed. .fam. This article does not detail that process but a tutorial is readily available at the PLINK homepage.
Computing - This GWAS was conducted using a high-powered computer with a 64 core cpu and 128GB of RAM available, certain steps require significant memory so replication on machines with less resources is not guaranteed.
File name - For the purposes of our analysis, our input file was 'allmerged_#'
R-Scripts - This method relies on a number of R-scripts previously generated by Marees et al., and adapted for use on our dataset. For replication, please download these scripts to your working directory.
		These R-scripts can be found as part of: (Marees, AT, de Kluiver, H, Stringer, S, Vorspan, F, Curis, E, Marie-Claire, C & Derks, EM 2018, 'A tutorial on conducting genome-wide association studies: Quality control and statistical analysis', Int J Methods Psychiatr Res, vol. 27, no. 2, p. e1608.)
		And downloaded from there.
Programs - Programs used for this analysis are Plink 1.9, Plink 2.0 and R.

########## Installing R onto Ubuntu subsystem ############

Run these lines (as root or by prefixing sudo) to tell Ubuntu about the R binaries at CRAN.

# update indices
sudo apt update -qq
# install two helper packages we need
sudo apt install --no-install-recommends software-properties-common dirmngr
# import the signing key (by Michael Rutter) for these repo
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9
# add the R 4.0 repo from CRAN -- adjust 'focal' to 'groovy' or 'bionic' as needed
sudo add-apt-repository "deb https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/"
Here we use lsb_release -cs to access which Ubuntu flavor you run: one of “hirsuite”, “groovy”, “focal”, “bionic”, …

Then run

sudo apt install --no-install-recommends r-base

##############################################################
############### START ANALISIS ###############################
##############################################################

# Change directory to a folder on your UNIX device containing all files from ‘1_QC_GWAS.zip’. 
cd HOME/{user}/{path/folder containing your files}

### Step 1 ### 

# Investigate missingness per individual and per SNP and make histograms.
plink --bfile allmerged_1 --missing    

# Delete SNPs with missingness >0.02.
plink --bfile allmerged_3 --geno 0.02 --make-bed --out allmerged_4

# Delete individuals with missingness >0.02.
plink --bfile allmerged_4 --mind 0.02 --make-bed --out allmerged_5

###################################################################
### Step2 ####

# Check for sex discrepancy.
# Subjects who were a priori determined as females must have a F value of <0.2.

plink --bfile allmerged_5 --check-sex 

# Generate plots to visualize the sex-check results. 
Rscript --no-save gender_check.R

# The following two scripts can be used to deal with individuals with a sex discrepancy.

# 1) Delete individuals with sex discrepancy.
grep "PROBLEM" plink.sexcheck| awk '{print$1,$2}'> sex_discrepancy.txt
# This command generates a list of individuals with the status “PROBLEM”.
plink --bfile allmerged_5 --remove sex_discrepancy.txt --make-bed --out allmerged_6 
# This command removes the list of individuals with the status “PROBLEM”.

###################################################
### Step 3 ### 

# Generate a bfile with autosomal SNPs only and delete SNPs with a low minor allele frequency (MAF).

# Select autosomal SNPs only (i.e., from chromosomes 1 to 22).
awk '{ if ($1 >= 1 && $1 <= 22) print $2 }' allmerged_6.bim > snp_1_22.txt
plink --bfile allmerged_6 --extract snp_1_22.txt --make-bed --out allmerged_7

# Generate a plot of the MAF distribution.
plink --bfile allmerged_7 --freq --out MAF_check
Rscript --no-save MAF_check.R

# Remove SNPs with a low MAF frequency.
plink --bfile allmerged_7 --maf 0.01 --make-bed --out allmerged_8
# 1073226 SNPs are left


####################################################
### Step 4 ###

# Delete SNPs which are not in Hardy-Weinberg equilibrium (HWE).

plink --bfile allmerged_8 --hardy

plink --bfile allmerged_8 --hwe 1e-6 --make-bed --out allmerged_hwe_filter_step1

plink --bfile allmerged_hwe_filter_step1 --hwe 1e-10 --hwe-all --make-bed --out allmerged_9


############################################################
### step 5 ###

# Generate a plot of the distribution of the heterozygosity rate of your subjects.
# And remove individuals with a heterozygosity rate deviating more than 3 sd from the mean.

plink --bfile allmerged_9 --exclude ./1_QC_GWAS/inversion.txt --range --indep-pairwise 50 5 0.2 --out indepSNP
# Note, don't delete the file indepSNP.prune.in, we will use this file in later steps.
plink --bfile allmerged_9 --extract indepSNP.prune.in --het --out R_check
# This file contains your pruned data set.

# Plot of the heterozygosity rate distribution
Rscript --no-save check_heterozygosity_rate.R

Rscript --no-save heterozygosity_outliers_list.R

sed 's/"// g' fail-het-qc.txt | awk '{print$1, $2}'> het_fail_ind.txt

# Remove heterozygosity rate outliers.
plink --bfile allmerged_9 --remove het_fail_ind.txt --make-bed --out allmerged_10


############################################################
### step 6 ###

# Check for relationships between individuals with a pihat > 0.2.
plink --bfile allmerged_10 --extract indepSNP.prune.in --genome --min 0.2 --out pihat_min0.2

### Note the --genome command is very memory intensive
### If you encounter memory issues the --memory command to dedicate more memory to the plink workspace to improve ability to handle large computations
### If you continue to encounter memory issues (relevant for large cohorts) the job can also be split up using the --parallel command.
plink --memory 120000 --bfile allmerged_10 --extract indepSNP.prune.in --genome --parallel 1 2 --min 0.2 --out pihat_min0.2
plink --memory 120000 --bfile allmerged_10 --extract indepSNP.prune.in --genome --parallel 2 2 --min 0.2 --out pihat_min0.2

### utilise the cat function to merge the files for next analysis 
cat pihat_min0.2.genome.1 pihat_min0.2.genome.2 > pihat_min0.2.genome.final

# The following commands will visualize specifically these parent-offspring relations, using the z values. 
awk '{ if ($8 >0.9) print $0 }' pihat_min0.2.genome.final>zoom_pihat.genome

# Generate a plot to assess the type of relationship.
Rscript --no-save Relatedness.R

# The generated plots show a considerable amount of related individuals (explentation plot; PO = parent-offspring, UN = unrelated individuals) in the Hapmap data, this is expected since the dataset was constructed as such.
# Note that for the UKB, since the samples have an age >40 it is more unlikely for there to be parent offspring relationships, there was 0 in our dataset.
plink --bfile allmerged_10 --filter-founders --make-bed --out allmerged_11

# Now we will look again for individuals with a pihat >0.2.
plink --bfile allmerged_11 --extract indepSNP.prune.in --genome --min 0.2 --out pihat_min0.2_in_founders


# For each pair of 'related' individuals with a pihat > 0.2, we recommend to remove the individual with the lowest call rate. 
plink --bfile allmerged_11 --missing

#extract the first of the two related individuals.
### Create a list of IID and FID of one related individual to extract
awk '{print $1" "$2}' pihat_min0.2.genome.final>0.2_low_call_rate_pihat.txt 

# Delete the individuals with the lowest call rate in 'related' pairs with a pihat > 0.2 
plink --bfile allmerged_11 --remove 0.2_low_call_rate_pihat.txt --make-bed --out allmerged_12

##########################################################
## Step 7

## Download 1000 Genomes data ##
# Note, this file is quite large (>60 gigabyte).  
wget ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/release/20100804/ALL.2of4intersection.20100804.genotypes.vcf.gz

# Convert vcf to Plink format.
plink --vcf ALL.2of4intersection.20100804.genotypes.vcf.gz --make-bed --out ALL.2of4intersection.20100804.genotypes
# Noteworthy, the file 'ALL.2of4intersection.20100804.genotypes.bim' contains SNPs without an rs-identifier, these SNPs are indicated with ".". This can also be observed in the file 'ALL.2of4intersection.20100804.genotypes.vcf.gz'. To check this file use this command: zmore ALL.2of4intersection.20100804.genotypes.vcf.gz .

### edit from original code: error with not recognising the @:#[b37],\$1, \$2 naming, resolved by using quotation marlk "" this resolves the issue to work as intended per:https://www.cog-genomics.org/plink/1.9/data#set_missing_var_ids 
plink --bfile ALL.2of4intersection.20100804.genotypes --set-missing-var-ids "@:#[b37]\$1,\$2" --make-bed --out ALL.2of4intersection.20100804.genotypes_no_missing_IDs

## QC on 1000 Genomes data.
# Remove variants based on missing genotype data.
plink --bfile ALL.2of4intersection.20100804.genotypes_no_missing_IDs --geno 0.2 --allow-no-sex --make-bed --out 1kG_MDS

# Remove individuals based on missing genotype data.
plink --bfile 1kG_MDS --mind 0.2 --allow-no-sex --make-bed --out 1kG_MDS2

# Remove variants based on missing genotype data.
plink --bfile 1kG_MDS2 --geno 0.02 --allow-no-sex --make-bed --out 1kG_MDS3

# Remove individuals based on missing genotype data.
plink --bfile 1kG_MDS3 --mind 0.02 --allow-no-sex --make-bed --out 1kG_MDS4

# Remove variants based on MAF.
plink --bfile 1kG_MDS4 --maf 0.05 --allow-no-sex --make-bed --out 1kG_MDS5

# Extract the variants present in HapMap dataset from the 1000 genomes dataset.
awk '{print$2}' allmerged_12.bim > allmerged_SNPs.txt
plink --bfile 1kG_MDS5 --extract allmerged_SNPs.txt --make-bed --out 1kG_MDS6

# Extract the variants present in 1000 Genomes dataset from the HapMap dataset.
awk '{print$2}' 1kG_MDS6.bim > 1kG_MDS6_SNPs.txt
plink --bfile allmerged_12 --extract 1kG_MDS6_SNPs.txt --recode --make-bed --out allmerged_MDS
# The datasets now contain the exact same variants.

## The datasets must have the same build. Change the build 1000 Genomes data build.
awk '{print$2,$4}' allmerged_MDS.map > buildallmerged.txt
# buildhapmap.txt contains one SNP-id and physical position per line.

plink --bfile 1kG_MDS6 --update-map buildallmerged.txt --make-bed --out 1kG_MDS7
# 1kG_MDS7 and HapMap_MDS now have the same build.

## Merge the HapMap and 1000 Genomes data sets

# Prior to merging 1000 Genomes data with the UKB data we want to make sure that the files are mergeable, for this we conduct 3 steps:
# 1) Make sure the reference genome is similar in the UKB and the 1000 Genomes Project datasets.
# 2) Resolve strand issues.
# 3) Remove the SNPs which after the previous two steps still differ between datasets.

# The following steps are maybe quite technical in terms of commands, but we just compare the two data sets and make sure they correspond.

# 1) set reference genome 
awk '{print$2,$5}' 1kG_MDS7.bim > 1kg_ref-list.txt
plink --bfile allmerged_MDS --reference-allele 1kg_ref-list.txt --make-bed --out allmerged-adj


# 2) Resolve strand issues.
# Check for potential strand issues.
awk '{print$2,$5,$6}' 1kG_MDS7.bim > 1kGMDS7_tmp
awk '{print$2,$5,$6}' allmerged_adj.bim > allmerged-adj_tmp
sort 1kGMDS7_tmp allmerged-adj_tmp |uniq -u > all_differences.txt

## Flip SNPs for resolving strand issues.
# Print SNP-identifier and remove duplicates.
awk '{print$1}' all_differences.txt | sort -u > flip_list.txt
# Generates a file of 812 SNPs. These are the non-corresponding SNPs between the two files. 
# Flip the 812 non-corresponding SNPs. 
plink --bfile allmerged-adj --flip flip_list.txt --reference-allele 1kg_ref-list.txt --make-bed --out corrected_allmerged

# Check for SNPs which are still problematic after they have been flipped.
awk '{print$2,$5,$6}' corrected_allmerged.bim > corrected_allmerged_tmp
sort 1kGMDS7_tmp corrected_hapmap_tmp |uniq -u  > uncorresponding_SNPs.txt
# This file demonstrates that there are 84 differences between the files.

# 3) Remove problematic SNPs from UKB and 1000 Genomes.
awk '{print$1}' uncorresponding_SNPs.txt | sort -u > SNPs_for_exlusion.txt
# The command above generates a list of the 42 SNPs which caused the 84 differences between the HapMap and the 1000 Genomes data sets after flipping and setting of the reference genome.

# Remove the 42 problematic SNPs from both datasets.
plink --bfile corrected_allmerged --exclude SNPs_for_exlusion.txt --make-bed --out allmerged_MDS2
plink --bfile 1kG_MDS7 --exclude SNPs_for_exlusion.txt --make-bed --out 1kG_MDS8

# Merge UKB with 1000 Genomes Data.
plink --bfile allmerged_MDS2 --bmerge 1kG_MDS8.bed 1kG_MDS8.bim 1kG_MDS8.fam --allow-no-sex --make-bed --out MDS_merge2


### use the Plink2.0 --PCA to produce a prinicpal components analysis, and use results as covariates to correct for population stratification
### using pca requires a large amount of memory, need to utilise high-powered computing for all cases where cohort is <100,000.
./plink2 --memory 127000 --bfile MDS_merge2 --extract indepSNP.prune.in --pca approx --out pca_results
### this will output a .eigenval & .eigenvec file type which is the output for a PCA, these will be used to visualise the population distribution

# Download the file with population information of the 1000 genomes dataset.
wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20100804/20100804.ALL.panel
# The file 20100804.ALL.panel contains population codes of the individuals of 1000 genomes.

# Convert population codes into superpopulation codes (i.e., AFR,AMR,ASN, and EUR).
awk '{print$1,$1,$2}' 20100804.ALL.panel > race_1kG.txt
sed 's/JPT/ASN/g' race_1kG.txt>race_1kG2.txt
sed 's/ASW/AFR/g' race_1kG2.txt>race_1kG3.txt
sed 's/CEU/EUR/g' race_1kG3.txt>race_1kG4.txt
sed 's/CHB/ASN/g' race_1kG4.txt>race_1kG5.txt
sed 's/CHD/ASN/g' race_1kG5.txt>race_1kG6.txt
sed 's/YRI/AFR/g' race_1kG6.txt>race_1kG7.txt
sed 's/LWK/AFR/g' race_1kG7.txt>race_1kG8.txt
sed 's/TSI/EUR/g' race_1kG8.txt>race_1kG9.txt
sed 's/MXL/AMR/g' race_1kG9.txt>race_1kG10.txt
sed 's/GBR/EUR/g' race_1kG10.txt>race_1kG11.txt
sed 's/FIN/EUR/g' race_1kG11.txt>race_1kG12.txt
sed 's/CHS/ASN/g' race_1kG12.txt>race_1kG13.txt
sed 's/PUR/AMR/g' race_1kG13.txt>race_1kG14.txt

# Create a racefile of your own data.
awk '{print$1,$2,"OWN"}' allmerged_MDS.fam>racefile_own.txt

# Concatenate racefiles.
cat race_1kG14.txt racefile_own.txt | sed -e '1i\FID IID race' > racefile.txt

# Generate population stratification plot.
# WORKAROUND FOR ERROR, MODIFY R SCRIPT par commands (new =F) and then change back to original i.e 
#par (new=T)
#Rscript MDS_merged.R 

### For PCA analysis in UKB use
Rscript PCA_Plot.R

## Exclude ethnic outliers.

# Using the visualisation from R script, determine the cutoffs to remove outliers 

### For UKB we used the PCA vector values to determine outlier
### where $3 is Principal component 1, and $4 is Principal component 2. Determine the bounds where the outliers are exluded and the primary cluster is included.

awk '{ if ($3 <0.016 && $4 >-0.023) print $1,$2}' pca_results.eigenvec > PCA_keep
### For QC check, produce a list of EIDs to remove, this can be checked between runs to see if there is any major variation in EIDs that are removed
awk '( if ($3 >0.016 && $4 <-0.023) print $1, $2)' pca_results.eigenvec > PCA_removelist

# Extract these individuals in UKB data.
plink --bfile allmerged_12 --keep PCA_keep --make-bed --out allmerged_13

### create a PCA for use as covariate in Final Analysis
./plink2 --memory 127000 --bfile allmerged_13 --extract indepSNP.prune.in --pca approx --out allmerged_13_pca

##########################################################################################################################################################################
## Step 7 - Association analysis

# Use plink2 to utilise newer glm model and improved linear association analysis
./plink2 --memory 127000 --bfile allmerged_13 --covar allmerged_13_pca.eigenvec --linear hide-covar --out linear_results_test
# You should now have an output file for your GWAS!


#### FINISH ANALYSIS ##########3
##########################################################################################################################
